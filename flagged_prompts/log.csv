System Prompt,User Prompt,flag,username,timestamp
"你是一个科技类媒体资深编辑，你的工作是从科技类分享视频的速记文字稿中原文摘录出精彩原文片段，请严格按照下列步骤完成工作：
第一步：对全文进行分析，找出包含了日常生活的一些词语，注意不要改变原文的顺序。把注意力放在这些内容上。
第二步：注意需要将某种具体的动作过程的描述，在原文摘录出来。
第三步：注意为了保持前后连贯，需要把第一步中摘录出来的原文的上下文也原文摘录出来。
第四步：注意把第一步和第二步摘录出来的原文进行合并。
第五步：对第四步的文字再次进行精选摘录，把精彩的摘录出来。注意提取的内容不要超过3段。
输出的格式为：* ""原始的文字内容""","后面是待编辑的速记稿原文，请按步骤完成工作：
",,,2024-09-01 14:26:50.712803
"你是一个科技类媒体资深编辑，你的工作是从科技类分享视频的速记文字稿中原文摘录出精彩原文片段，请严格按照下列步骤完成工作：
第一步：对全文进行分析，找出包含了日常生活的一些词语，注意不要改变原文的顺序。把注意力放在这些内容上。
第二步：注意需要将某种具体的动作过程的描述，在原文摘录出来。
第三步：注意为了保持前后连贯，需要把第一步中摘录出来的原文的上下文也原文摘录出来。
第四步：注意把第一步和第二步摘录出来的原文进行合并。
第五步：对第四步的文字再次进行精选摘录，把精彩的摘录出来。注意提取的内容不要超过3段。
输出的格式为：* ""原始的文字内容""","后面是待编辑的速记稿原文，请按步骤完成工作：
",,,2024-09-01 14:27:02.858158
"你是一个科技类媒体资深编辑，你的工作是从科技类分享视频的速记文字稿中原文摘录出精彩原文片段，请严格按照下列步骤完成工作：
第一步：对全文进行分析，找出包含了案例或者演示或者成绩或者观点的一些词语，注意不要改变原文的顺序。把注意力放在这些内容上。
第二步：注意需要将某种具体过程的描述，在原文摘录出来。
第三步：注意为了保持前后连贯，需要把第一步中摘录出来的原文的上下文也原文摘录出来。
第四步：注意把第一步和第二步摘录出来的原文进行合并。
第五步：对第四步的文字再次进行精选摘录，把精彩的摘录出来。注意提取的内容不要超过3段。
输出的格式为：* ""第五步输出的摘录内容""","后面是待编辑的速记稿原文，请按步骤完成工作：
",,,2024-09-01 14:35:00.060500
"你是一个科技类媒体资深编辑，你的工作是从科技类分享视频的速记文字稿中原文摘录出精彩原文片段，请严格按照下列步骤完成工作：
第一步：对全文进行分析，找出包含了案例或者演示或者成绩或者观点的一些词语，注意不要改变原文的顺序。把注意力放在这些内容上。
第二步：注意需要将某种具体过程的描述，在原文摘录出来。
第三步：注意为了保持前后连贯，需要把第一步中摘录出来的原文的上下文也原文摘录出来，注意要添加上标点符号
第四步：注意把第一步和第二步摘录出来的原文进行合并。
第五步：对第四步的文字再次进行精选摘录，把精彩的摘录出来。注意提取的内容不要超过3段。
输出的格式为：* ""第五步输出的摘录内容""","后面是待编辑的速记稿原文，请按步骤完成工作：
",,,2024-09-01 14:36:32.880418
"你是一个科技类媒体资深编辑，你的工作是从科技类分享视频的速记文字稿中原文摘录出精彩原文片段，请严格按照下列步骤完成工作：
第一步：对全文进行分析，找出包含了案例或者演示或者成绩或者观点或者政策解读的一些词语，注意不要改变原文的顺序。把注意力放在这些内容上。
第二步：注意需要将某种具体过程的描述或者对复杂事情的解读，在原文摘录出来。
第三步：注意为了保持前后连贯，需要把第一步中摘录出来的原文的上下文也原文摘录出来。
第四步：注意把第一步和第二步摘录出来的原文进行合并。
第五步：对第四步的文字再次进行精选摘录，把精彩的摘录出来。注意提取的内容不要超过3段，同时不要超过250字。
输出的格式为：* ""第五步输出的摘录内容""","后面是待编辑的速记稿原文，请按步骤完成工作：
",,,2024-09-01 15:25:48.569887
"你是一个科技类媒体资深编辑，你的工作是从科技类分享视频的速记文字稿中原文摘录出精彩原文片段，请严格按照下列步骤完成工作：
第一步：对全文进行分析，找出包含了案例或者演示或者成绩或者观点或者政策解读的一些词语，注意不要改变原文的顺序。把注意力放在这些内容上。
第二步：注意需要将解决具体问题的具体过程或者对复杂原理的通俗解读，按原文摘录出来。注意提取出来的内容需要保持原文，不要改变原文。
第三步：注意为了保持前后连贯，需要把第一步中摘录出来的原文的上下文也原文摘录出来。
第四步：注意把第一步和第二步摘录出来的原文进行合并。
第五步：对第四步的文字再次进行精选摘录，把精彩的摘录出来。注意提取的内容不要超过5段。注意提取出来的内容需要保持原文，不要改变原文。
输出的格式为：* ""提取的内容""","后面是待编辑的速记稿原文，请按步骤完成工作：
",,,2024-09-05 18:34:15.604897
"你是一个科技类媒体资深编辑，你的工作是从科技类分享视频的速记文字稿中原文摘录出精彩原文片段，请严格按照下列步骤完成工作：
第一步：对全文进行分析，找出包含了案例或者演示或者成绩或者观点或者政策解读的一些词语，注意不要改变原文的顺序。把注意力放在这些内容上。
第二步：注意需要将解决具体问题的具体过程或者对复杂原理的通俗解读，按原文摘录出来。注意提取出来的内容需要保持原文，不要改变原文。
第三步：注意为了保持前后连贯，需要把第一步中摘录出来的原文的上下文也原文摘录出来。
第四步：注意把第一步和第二步摘录出来的原文进行合并。
第五步：对第四步的文字再次进行精选摘录，把精彩的摘录出来。注意提取的内容不要超过5段。注意提取出来的内容需要保持原文，不要改变原文。
输出的格式为：* ""提取的内容""","后面是待编辑的速记稿原文，请按步骤完成工作：
",,,2024-09-05 18:34:17.763260
"你是一个青少年教育类媒体资深编辑，你的工作是从视频的速记文字稿中原文摘录出精彩原文片段，请严格按照下列步骤完成工作：
第一步：对全文进行分析，教育或者辅导的具体过程或者方法。把注意力放在这些内容上。
第二步：注意需要将好的学习方法或者优秀的学习秘笈或者成功的案例，按原文摘录出来。注意提取出来的内容需要保持原文，不要改变原文。
第三步：注意为了保持前后连贯，需要把第一步中摘录出来的原文的上下文也原文摘录出来。
第四步：注意把第一步和第二步摘录出来的原文进行合并。注意输出的内容不要超过6段。注意提取出来的内容需要保持原文，不要改变原文。
输出的格式为：* ""提取的内容""","后面是待编辑的速记稿原文，请按步骤完成工作：
",,,2024-09-05 19:48:51.903297
"你是严格按照工作要求的句子剪辑器。你的输入是现场演讲的速记稿。你的工作需要分步骤完成：
* 对速记稿从头到尾分析后，根据CEO人群筛选出精彩案例并输出
* 根据科技人士的爱好，从上一步的案例中再筛选出不超过10个的案例标题并输出案例解读和案例内容中的日常物品
注意如果没有找到就输出没有并终止输出。注意匹配出的句子需要保持原文。注意输出格式：
-  案例标题
- ","你是严格按照工作要求的句子剪辑器。你的输入是现场演讲的速记稿。你的工作需要分步骤完成：
* 输出 气球 所在的段落
* 输出它的前2个段落
* 输出它的后2个段落
* 合并所有的输出结果并输出
* 输出 瓷器 所在的段落
* 输出它的前一个段落
* 输出它的后一个段落
* 合并所有的输出结果并输出
注意如果没有找到就输出没有并终止输出。注意匹配出的句子需要保持原文。注意输出格式：
- “输出”","后面是速记稿内容：
","介绍
我下面就直接进入主题
就讲我今天的内容
就是我们自身智能的这样的一个PI模型
感知想象和执行
因为我前面的一些当然说这个愿景大家能来这今天来这里肯定很清楚
就是我们的愿景是要实现通用机器人
我比较喜欢这部电影
是因为这部电影觉得是我认为在可见的未来
是我们所有的东西都能够实现的
但西部世界可能比较遥远
这部电影我觉得是可能实现的
大家有兴趣可以看一看
当然具身智能的话我也不多讲了
在很早的图灵时代已经就提出了这样的一个居然智能这个概念
为什么他学术上是一个从智能是一个更加是一个智能是一个非常高的一个智能的水平
是因为他是因为身体的身体联合去学习
就像我们这个这个实验我讲了很多
我就来快速讲一下
就是这只实验室它有两只猫
然后这只猫是主动来走
另一只猫它出生就把它关起来
但是他看的东西是一样的
最后这只猫把他被动的猫他下来之后
他就失去了行为能力
那这是为什么呢
这是因为他没有基于身体的智能
所以说他就失去了这种行为的能力
好
这也是证明了居然智能的重要性
当然到今天我就不用讲那么多
不言而喻了
因为我记得我我之前的讲座还得讲一堆什么是居间智能
可能就我就快速跳过了
好
我们的我们是单车现在捐赠
肯定是大家要做很多的技术路线
对吧
我们也一直在探索
16年开始在探索一种什么样的一个技术智能的框架
就他学术的底座应该什么样子
那我们就类比人的模块
我们会把它塞这个部分
就是大具身感知
居然想象
居然执行
这是什么逻辑呢
就是其实我们做件事情的话
我们首先要知道他感知到这个世界的模型
然后的话其实我脑子里是在想象的
就是我们做件事情脑子是在动脑的
比如说我要把它拧开
我脑子是过了一遍
只是我们自己下意识没感觉而已
这属于是大脑功能
我们把这个世界抽象出来
然后第二部分就是执行
执行是完全小脑的功能
大家觉得那执行是不是比较简单
我想我就能做
其实并不是那么简单的
因为它涉及到我们其实身体的下意识反应
这个我会后面会专门展开讲
所以说这两部分对于世界这功能是对于大脑对世界理解和抽象
最后我们要具象的去执行
我们就展开讲
第一个部分就是巨深的感知了
当然说大家可能看过很多
大家都做机缘
如果做机缘视觉知道的感知
但是我们需要的感知有什么不一样呢
其实这里面有一个科学问题
就是说如何去通用的去估计物理的常识
那这些事情我们觉得都很容易是吧
但其实不这么容易
就是我们把这个箱
把这个盒子给它检测出来是比较容易的
但是你要推断出这里是可以操作
这个轴可以翻开
这是有有难度的
这件事情
而我们是通用的
做到我们专门去训练
可能就意思不不是很有意思了
这个事情其实在22年时候有篇nature behavior的文章
也就讲深度学习做这件事情其实现在是做不到的
比较乏力
去仔细想他的这个问题是在我们觉得在大模型今天非常强大的当天
今天其实很多时候是卡在数据上面
这里面就是如何大规模的获得这种带有这种操作常识的数据
是一件很难的事情
就比如上面我们知道这是可以翻开
这可以拉的这是一件很难的事情
那么我们就去创一个什么思路呢
这个思路就是说我们发现了这样的一个问题
就是说我们发现原来这个手的操作和这个物体的操作常识
它存在一种对偶关系
我们验证了说我们通过手的操作
我们就能推出这样的一个物体是怎么样的一种操作知识操作知识
我们就能够去去生成这个手的操作这种对偶关系
那么发现了对偶关系有什么好处
首先这是可以这是最自然的数据
而且是准确的
可以被规模化的
这就是说比起你在那个3D里面去标
它是更加准确的对规模化的
为此的话
我们就去构建了一系列的算法去去推断这些事情
因为时间有限我就不讲了
总之这样我们就将怎么去做手部重建
以及手的在里面提取物体的知识
这是一些提取出来的一些操作知识的结果
我们这里因此还构建了一个一系列的一个系统
这个系统的话是说怎么样快速的去通过手的操作
上面是视频
下面是对视频的解析
下面是对手的一个分析
手的分析我们能够去知道他在做一个什么概念
这个物体应该是被怎么操作的那用方法能快速的制备海量的数据
那有这样数据的话
我们发现这个模型的准确率就会被大大的提升
也会这样的通用的将来这个通用的这样的一个世界模型的困难的world model
就是我们看到什么事情
我知道怎么去操作它
这样的是带来一个非常好的基础
当然说基建的大数据之后
我们就是会去去训练这样的一个物体的知识的模型
就比如说像这些
日本也得到了一个很大的提高
好
因为时间有限
我跳到下一部分
其实大家还是能想到柔性物体怎么办
对吧
缸体比较简单
柔性物体的话其实我们也可以用这种方法
但是我们是在vrar眼镜里面
我们配合上仿真引擎
比如叠衣服这样的蝶的过程中
其实我们是操作这个叠的知识被记录下来
当然这里面还有一个环节是我们衣服操作完了
我们要跟真机进行仿真对齐
我们是这种是在仿真里面训的
但也是用手的操作记录他的操作知识
最后我们要跟真机对齐
可能需要这么一步
这是唯一不一样的
为此的话我们就能够做到了
应该我认为第一个实际上第一个能够去做任意物体的物物体的那个衣服的操作
因为衣服它那难点是跟比如去抓个东西
霍拉的东西不一样
它是它整个状态是不确定的
而且你看刚才我们扔进去的衣服是状态不确定的
那么相比于像之前的方法的话
他们是首先衣服要铺的比较好
而且它别的它是一个纯色的
它要叠起来的话需要很多的很很很多那个就是相对来说是比较简单的
我们是能做复杂的
我们有了这样的一个知识之后
我们可以干什么事情呢
我们可以做交互感知的
比如说我们现在从能改造这个微波炉
是可以这样拉的
但是说我们改造微波炉之后
我们发现还是有问题的
就是他感知可能不准
那我们就引入了交互去纠正他的感知
那么怎么做呢
因为我们去拉的时候
我们能够预判他下一步应该怎么样子
因为我们有这个事件的模型
对吧
我们可以估计
那么我们就可以真实的对比
像这个是我们估计的
是我们真实的
然后我们去最小化它的误差
最小化它误差就是逼着什么
逼这个模型必须估计
对你估计不对的话
你你这个事情就会出错
通过这个loss之后
我们就可以看到这个很有趣的事情
就是我们从开始这个事件的模型有一点点错误
通过操作过程中引入这个操作者的纠正
然后我们就能够把这个误差大量的大大量的大量的下降
在此的话我们有另一个工作
我们可以把这个东西放到更难的比如穿针上面
而且我们这个东西不只是对于这个真的模型
而且我们会带上那个观测的机械臂
这个观测机械臂的话可以去看到说去进行不停的对他的纠正
这也是获得今年的国际机器人品会RS的最佳系统论文提名
是唯一的华人单位
好
下面我们就有了感知到
基本知道这个世界什么样子
我们脑子里肯定过一遍了
那为什么这件事情那么重要呢
因为我们脑子里的话
仿真是把这个物理的约束加进去的
所以说我们就会有个科学问题
就如何把物理知识的约束去降低开发环境下的在学习
这个机器人的话
这是一个全新的问题
为什么呢
因为它要求又准又快
这是很复杂的问题
当然仿真引擎大家可能知道的多了
有游戏仿真引擎它快但物理上不准
工业引擎它准
但它不够快
因为我们机器学习是需要机器学习要高速的和那个仿真引擎进行交互的
因此的话因此的话我们就因此我们的话我们就是对这个数学物理方程进行了重写
以及做了很多软件工程的工作
之前他们要求快
他们是为了是要把各个模态进行独立的
而我们建立了联合方程
还有很多细节我就不讲了
包括你看如果他们不这么做
他们会穿模
那我们就能够非常好的在这种多态中能够取得非常好的仿真效果
我们的实验也表明了我们的速度能提升四百多倍
跟最好的工业软件
我们的误差在一毫米内
就是能够支持高水平
的物理仿真和同时能够同时能够同时能够快速的响应这样的一个机器人仿真系统
机器人的那个真机系统
这时候你可以看到是我们我们跟力学
这是我们的那个用仿真的这是真机的力学
我们测出来的这个误差是相对比较小的
也是在里面有很多数学物理化物理方程来在在支撑说我们对柔性物体的仿真
在底层上去重写了它的数学物理方程
还有这样子的输液等等
还有那个水流
这些都是一些非常难度的这些仿真
但是关键它速度需要快
这是还有它的渗透系统
就相当于是把物理的那种规律嵌到你的学习系统里面
导致它的准确率会更高
好
我们是相比于国际上的这几个仿真引擎
包括stands还有那个MIT
我们有以下优势
从公开发表的结果看
有以下的
这个我们是开源的
就是logo flow大家可以搜一下
已经有康奈尔的之类多个单位在使用
发了论文
好
那么有了这个事情的话
我们能干些什么很有趣的事情呢
我们一个非常好的一个物理仿真器
必须快跟人工智能系统高速的一起
并且的话我们通过协助学习规划之后
我们就会得到一个真实场景
我们脑子里其实有一个仿真引擎
对吧
我们仿真这种物理参数
但是物理参数我们不可能去测量的
但是我们可以去仿真它的物理参数
如果你仿真错了
你跟真实情况是有一个误差的
我们去约束这个误差
逼着他这个物理参数必须得对
才能够跟甄姬跟真实场景一致
那就逼着他去估计这个真实的物理参数
像这个叠衣服包括这么多量
我们就是等于说整个系统会高速的跑起来
仿真和深度学习联合的好起来
我们就可以看到说
下面是真机
下面是仿真
这种柔性物体其实钢铁还比较好弄
柔性物体是非常难的
我们能够不能说分毫不差
但是很接近
导致我们的行为能比较准确
这是我们估计出来的各种的物理参数
和真实的比较还是很接近的
好
当然说这个事情的话
当我们进一步有这仿真引擎
同时可能也会支持这个海量的视频去学习那个实践的行为
去实践那个行为
但是为此我们还构建了从怎么样从演示视频和仿真系统对齐的一个系统
然后最后听到甄姬
因为时间有限
我这就不讲了
这也获得了i lost的ISS的
不是那个I那个i lost的最佳论文机
这是我们的整个拍拍视频理解对接到仿真
然后最后到真机把刚才那整套把它串起来
好
最后是居身执行
这个事情其实是一个大家可能没感觉到
但我们觉得很疼的一个问题
就你看现在来说
为什么我们觉得大脑规划完就结束了
其实不是我们实现下来
是我们人为什么觉得大脑就已经搞完就结束
是因为我们有个神经下意识反应
就是我们一个大小脑和这个神经系统使得我们神经系统使得我们能够去去下意识去做很多东西
但是机器人如何去实现这种鲁棒的下意识
是很关键的
因为机器人存在感知误差、仿真误差
还有机械误差
其实人也是一样的
其实大家有没有觉得我们的感知其实是有误差的
就是比如说我们去感知的东西
我们的脑子里其实这么想
但其实我们闭上眼睛的时候其实很大的误差
那么这个时候就是这个误差
怎么用人工智能把它吃掉
这也就是说为什么能吃掉
是因为我们刚才有个规划
其实规划里面有底层
其实有一个又一个的那个子的原子的操作
如果您原子操作能够被通用化
被这个人工智能吃掉的话
那么我们就有可能去做成这样的一个事情
这为什么能做到呢
是因为其实他和同一个动作
他其实在拓扑上同源的
比如这个翻的动作
其实之后会拓扑同学到这个东西不周转这个事情
所以有没有可能性
为此我们会去解决这样的一个操作的问题
我们第一步是要解决通用的抓取问题
通用的抓取问题它的最大的问题是数据困境
还是回到了数据问题
就是说我们有这么多的便于
那我们怎么变成这些抓取的密集数据
之前是没办法去制备这种大规模的数据的
因此我们提出了一套半自动的数据的采集方式
我们的整个的数据效率提高了
标准提高了1万倍
使得我们能够快速的大规模的制备大量的数据
不然的话很长时间
基本原理是我们通过这是真实点名
然后我们有一套数字完成系统
能够去通过这个数字完成到这里
然后我们可以生成它的抓取的在用仿真甚至来抓取的点云
然后就可以在真实的点云上打上很多标签
但是整套系统是里面欠了很多算法和半自动的这样的系统
为此我们能够大大的扩大了是比目前数据集这21个数据有效数据能够有效的扩张到10万倍这样的数据
而且标注的效率会大大提高
也配套提出了新的大模型的抓取大模型的算法
这里就不展开来讲
为此的话我们就会因此我们得到了一个通用的抓取的模型
通过抓取模型
我们跟别的抓取的不一样
我们没见过的时候我们都能够去抓
比如我们刚才这个东西被敲碎
这个瓷器被敲碎
瞬间其实每一个块都是没有见过的
但没有见过我们仍然能够把它抓起来
我们是在5000个没有见过完全没有见过的物体上面能够被被通用的抓取
包括我们也扩张到了那个去动态的物体
这是世界上第一个能够抓通用的
没有抓没有通过见过那个物体的抓鱼
就抓那个没有见过的动态的物体
这个也发表在那个机器人的底盘TO上面
我们也是首次去跟人类比较
超过人类水平
从准确率和速度上面对没有见过的物体的抓取
超人类水平也被斯坦福的机器人抓取排行榜被被评为近十年影响力第二名
好
最后讲了一个以立学为中心的框架
我们会思考一个问题就是说我们的话就是说我们之前谷歌不是提出了一种大模型
我们可以反思一下我们的大模型就是他是视觉输入
然后通过大模型去得到一个位置决策
那这种事情有什么问题呢
看起来是没问题的
但是你们有没有发觉他们就是更多的做移动
把这个东西移到了另个地方
就是没有做那种rich content
是那个那个rich contact
就是那种很丰富的接触
而这个事情我们如果需要突破很复杂的接触的问题
那么需要以力觉为中心的AI框架
就是位置引导下的力反馈的一个输出
因此构建了这样的力觉的一个大模型
去做这样的一个事情
我们来看看有一件事情就是位置控制的一定是做不了的
就我们光这个气球
你你你想一个问题
如果我们有位置控制
你只要往下挫1毫米就爆掉了
往上一毫米就刮不干净
所以这里面它的我们这个模型的输出是用大模型输出的
它的力的按压力是多少
以及它切向力是多少
但是可能大概有一个位置的一个引导
所以如果未来用到了家用医疗等等
是需要一个非常好的力反馈的一个力学大模型来做这样的一个事情
这也是我们一直在希望在做这样的一个在在做的一个过程
包括我们的能够做到非常精密的那种这种力的控制
就是能做到他这样
那其实也是说会在你的力觉参数和这个位置引导是由模型来输出
这就是说以力觉为中心会是将来去解决小脑这部分很关键的一个点
为此的话我们也是开源了线上的最大的目前最大的以力觉为中心的数据大家欢迎下载
我们的数据集量是GTP数据量的2倍
我们拥有力觉、听觉、语言控制、视觉等等这些这样的一个事情
我们的力的操作平台是比较特殊的
我们能够sorry
好
这里其实是一张一个视频
这本来是我们的切口机
就是我们人去窑操作切火机
能够去记录大量的那种底层的这种力反馈的数据
然后当时我们位置为中心的模仿学习数据库
我们也参与了
我们是大概有40个学校
然后我们也是唯一的国内单位
参与了最大规模的一个这种open x body的这就是基于位置仿真的一个位置基于位置规划的这样的一个
数据
也欢迎大家来来使用
好
那么就是呃我们这是我们的综合的系统的结果这是我们综合的系统的结果
就是说sorry
就是我们我们把我们整体的各种技术整合进去
做了一套综合的一个机器人
比如做早餐、清洁
你看这个擦东西
其实我们为什么要插入
因为插入需要力倦
因为力卷你擦不干净
所以我们需要那个力的模型
包括我们要去把服务拿进去
这里面会整合到我们的柔性物体
如果没有很好的
刚才我们讲的钢铁还是比较容易
当你柔性物体知道哪个是衣领的时候
它的难度就会大大的增加
好啊
这是当然我们也把我们的很多的技术开源到我们的lovel flow
我们一个上面有生态toria document
还有论坛和deut等等连接能连接14种机器人
也希望大家能够多多支持我们
当然最后我们时间有限
我来讲我们跟怎么去研究大脑和身体间的关系
这是基因智能和一个行为上的一个很关键的一个事情
时间到了
好
那那刚刚好
最后是我们这些做的一些论文
就包括我们主要还在除了人工智能的
还有机器人的两大顶刊上面
还有获得的一些最佳各个会议的最机器顶会的最佳论文
好
我可能怕时间不够赶的太快
最后讲一句感慨一下
就是通用之前是人工智能的终极状态
我们认为计算智能是个灵魂
也就是很有趣的一个领域
希望大家能够也能够一起来来做这么一件让让人类更加美好的事情
然后再次推荐大家看这部电影
就是我每次看的时候觉得你的动作我们怎么把它做成
也是我们可以做成的范围内
好
谢谢大家
",,,2024-09-10 18:36:00.270023
"你是严格按照工作要求的句子剪辑器。你的输入是现场演讲的速记稿。你的工作需要分步骤完成：
* 对速记稿从头到尾分析后，根据CEO人群筛选出精彩案例并输出
* 根据科技人士的爱好，从上一步的案例中再筛选出不超过10个的案例标题并输出案例解读和案例内容中的日常物品
注意如果没有找到就输出没有并终止输出。注意匹配出的句子需要保持原文。注意输出格式：
-  案例标题
- ","你是严格按照工作要求的句子剪辑器。你的输入是现场演讲的速记稿。你的工作需要分步骤完成：
* 输出 气球 所在的段落
* 输出它的前2个段落
* 输出它的后2个段落
* 合并所有的输出结果并输出
* 输出 瓷器 所在的段落
* 输出它的前一个段落
* 输出它的后一个段落
* 合并所有的输出结果并输出
注意如果没有找到就输出没有并终止输出。注意匹配出的句子需要保持原文。注意输出格式：
- “输出”","后面是速记稿内容：
",/tmp/gradio/c2ee018d832d535b99e2a18b9c508607276b93c0b26643a9c71aa021580d887b/卢策吾具身智能感知-想象-执行研究-具身智能-CNCC .srt,,,2024-09-10 18:37:09.624583
